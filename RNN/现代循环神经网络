门控循环单元(GRU)
  不是每个观察值都是同等重要
  想只记住相关的观察需要：
    能关注的机制(更新门)
    能遗忘的机制(重置门)

  Ht分为三种极端情况：
    1.只和Ht-1相关--->Zt为接近于1
    2.只和Xt相关--->Rt接近于0，Zt接近于0
    3.和原来的RNN一样--->Rt接近于1，Zt接近于1




长短期记忆网络(LSTM):
  有两个状态，一个C(记忆单元)，一个H 
  忘记门：将值朝0减少
  输入门：决定是不是忽略掉输入数据
  输出门：决定是不是使用隐状态

  候选记忆单元：和RNN的Ht更新算法一样


深度循环神经网络：
  如何得到更多的非线性性：


  每个隐藏状态由左边和下边的状态实现
