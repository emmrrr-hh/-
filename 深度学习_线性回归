线性回归的相关定义：
      线性模型可以看作单层神经网络：输入层和输出层。
    衡量预估质量：比较真实值和估计值
      例如：平方损失
    训练数据（通常越多越好）：
    参数学习：
    训练损失函数：例如房价预估：降低损失函数到最低；
    基础优化算法：
      1.梯度下降：重复迭代参数；学习率(超参数)；
        由于样本数量有时可能过大，因此可以在一部分样本上来进行梯度下降，因此引入另一个超参数b（批量大小）


线性回归的实现：
  1.从零开始
      构造一个人造数据集：
        def synthetic_data(w,b,num_examples):
          X=torch.normal(0,1,(num_examples,len(w)))
          y=torch.matmul(X,w)+b
          y+=torch.normal(0,0.01,y.shape)
          return X,y.reshape((-1,1))




2.线性回归的简洁实现
